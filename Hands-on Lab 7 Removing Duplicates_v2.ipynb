{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Removing Duplicates**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will focus on data wrangling, an important step in preparing data for analysis. Data wrangling involves cleaning and organizing data to make it suitable for analysis. One key task in this process is removing duplicate entries, which are repeated entries that can distort analysis and lead to inaccurate conclusions.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify duplicate rows  in the dataset.\n",
    "2. Use suitable techniques to remove duplicate rows and verify the removal.\n",
    "3. Summarize how to handle missing values appropriately.\n",
    "4. Use ConvertedCompYearly to normalize compensation data.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset into a DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the dataset using pd.read_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the dataset\n",
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to ensure it loaded correctly\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: If you are working on a local Jupyter environment, you can use the URL directly in the <code>pandas.read_csv()</code>  function as shown below:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Identifying Duplicate Rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1: Identify Duplicate Rows**\n",
    "  1. Count the number of duplicate rows in the dataset.\n",
    "  2. Display the first few duplicate rows to understand their structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(65437, 114)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "Total_duplicates_count = df.duplicated().sum()\n",
    "print(Total_duplicates_count)\n",
    "\n",
    "Total_duplicates = df[df.duplicated(keep=False)]\n",
    "Total_duplicates.head(10)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Removing Duplicate Rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2: Remove Duplicates**\n",
    "   1. Remove duplicate rows from the dataset using the drop_duplicates() function.\n",
    "2. Verify the removal by counting the number of duplicate rows after removal .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65437, 114)\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "df_cleaned = df.drop_duplicates(keep='first') \n",
    "print(df.shape)\n",
    "\n",
    "# Duplicates seems to be already removed from file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3: Identify and Handle Missing Values**\n",
    "   1. Identify missing values for all columns in the dataset.\n",
    "   2. Choose a column with significant missing values (e.g., EdLevel) and impute with the most frequent value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Amount  Percentage (%)\n",
      "ResponseId                           0            0.00\n",
      "MainBranch                           0            0.00\n",
      "Age                                  0            0.00\n",
      "Employment                           0            0.00\n",
      "Check                                0            0.00\n",
      "EdLevel                              0            0.00\n",
      "AISelect                          4530            6.92\n",
      "LearnCode                         4949            7.56\n",
      "NEWSOSites                        5151            7.87\n",
      "YearsCode                         5568            8.51\n",
      "LanguageHaveWorkedWith            5692            8.70\n",
      "SOAccount                         5877            8.98\n",
      "SOVisitFreq                       5901            9.02\n",
      "DevType                           5992            9.16\n",
      "SOComm                            6274            9.59\n",
      "SOHow                             6475            9.90\n",
      "Country                           6507            9.94\n",
      "OpSysPersonal use                 7263           11.10\n",
      "NEWCollabToolsHaveWorkedWith      7845           11.99\n",
      "SurveyEase                        9199           14.06\n",
      "SurveyLength                      9255           14.14\n",
      "LanguageWantToWorkWith            9685           14.80\n",
      "OfficeStackSyncHaveWorkedWith     9892           15.12\n",
      "RemoteWork                       10631           16.25\n",
      "CodingActivities                 10971           16.77\n",
      "OpSysProfessional use            12464           19.05\n",
      "ToolsTechHaveWorkedWith          12955           19.80\n",
      "NEWCollabToolsWantToWorkWith     13350           20.40\n",
      "YearsCodePro                     13827           21.13\n",
      "LanguageAdmired                  14565           22.26\n",
      "NEWCollabToolsAdmired            14726           22.50\n",
      "DatabaseHaveWorkedWith           15183           23.20\n",
      "LearnCodeOnline                  16200           24.76\n",
      "OfficeStackAsyncHaveWorkedWith   17344           26.50\n",
      "OrgSize                          17957           27.44\n",
      "PurchaseInfluence                18031           27.55\n",
      "OfficeStackSyncWantToWorkWith    18726           28.62\n",
      "Currency                         18753           28.66\n",
      "ToolsTechWantToWorkWith          19353           29.58\n",
      "AISent                           19564           29.90\n",
      "SOPartFreq                       20200           30.87\n",
      "BuyNewTool                       20256           30.95\n",
      "WebframeHaveWorkedWith           20276           30.99\n",
      "OfficeStackSyncAdmired           20725           31.67\n",
      "AIThreat                         20748           31.71\n",
      "TBranch                          20960           32.03\n",
      "AISearchDevHaveWorkedWith        20984           32.07\n",
      "ToolsTechAdmired                 21440           32.76\n",
      "TechEndorse                      21769           33.27\n",
      "BuildvsBuy                       22079           33.74\n",
      "DatabaseWantToWorkWith           22879           34.96\n",
      "PlatformHaveWorkedWith           23071           35.26\n",
      "AIEthics                         23889           36.51\n",
      "TechDoc                          24540           37.50\n",
      "MiscTechHaveWorkedWith           25994           39.72\n",
      "OfficeStackAsyncWantToWorkWith   26471           40.45\n",
      "DatabaseAdmired                  26880           41.08\n",
      "WebframeWantToWorkWith           26902           41.11\n",
      "AIChallenges                     27906           42.65\n",
      "AIAcc                            28135           43.00\n",
      "OfficeStackAsyncAdmired          28233           43.15\n",
      "AIComplex                        28416           43.42\n",
      "AIBen                            28543           43.62\n",
      "AISearchDevWantToWorkWith        28736           43.91\n",
      "AISearchDevAdmired               29894           45.68\n",
      "AIToolCurrently Using            30365           46.40\n",
      "WebframeAdmired                  30494           46.60\n",
      "PlatformWantToWorkWith           30905           47.23\n",
      "CompTotal                        31697           48.44\n",
      "MiscTechWantToWorkWith           32473           49.62\n",
      "PlatformAdmired                  34060           52.05\n",
      "AIToolInterested in Using        34746           53.10\n",
      "ICorPM                           35636           54.46\n",
      "WorkExp                          35779           54.68\n",
      "MiscTechAdmired                  35841           54.77\n",
      "JobSatPoints_6                   35987           54.99\n",
      "JobSatPoints_10                  35987           54.99\n",
      "JobSatPoints_9                   35981           54.99\n",
      "JobSatPoints_8                   35981           54.99\n",
      "JobSatPoints_7                   35989           55.00\n",
      "JobSatPoints_11                  35992           55.00\n",
      "JobSatPoints_5                   36026           55.05\n",
      "JobSatPoints_4                   36044           55.08\n",
      "JobSatPoints_1                   36113           55.19\n",
      "JobSat                           36311           55.49\n",
      "TimeSearching                    36526           55.82\n",
      "Industry                         36579           55.90\n",
      "TimeAnswering                    36593           55.92\n",
      "ProfessionalQuestion             36630           55.98\n",
      "Knowledge_1                      36773           56.20\n",
      "ProfessionalCloud                36946           56.46\n",
      "Frequency_2                      37073           56.65\n",
      "Frequency_1                      37068           56.65\n",
      "Frustration                      37186           56.83\n",
      "Knowledge_3                      37342           57.07\n",
      "Knowledge_4                      37407           57.16\n",
      "Knowledge_2                      37416           57.18\n",
      "Knowledge_5                      37557           57.39\n",
      "Knowledge_6                      37573           57.42\n",
      "Knowledge_7                      37659           57.55\n",
      "ProfessionalTech                 37673           57.57\n",
      "Knowledge_8                      37679           57.58\n",
      "Frequency_3                      37727           57.65\n",
      "Knowledge_9                      37802           57.77\n",
      "AINextMore integrated            41009           62.67\n",
      "AIToolNot interested in Using    41023           62.69\n",
      "ConvertedCompYearly              42002           64.19\n",
      "EmbeddedHaveWorkedWith           43223           66.05\n",
      "EmbeddedWantToWorkWith           47837           73.10\n",
      "EmbeddedAdmired                  48704           74.43\n",
      "AINextMuch more integrated       51999           79.46\n",
      "AINextNo change                  52939           80.90\n",
      "AINextLess integrated            63082           96.40\n",
      "AINextMuch less integrated       64289           98.25\n",
      "Most filled in values: Bachelor’s degree (B.A., B.S., B.Eng., etc.)\n",
      "Amount of missing values after imputation EdLevel: 0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "missing_count = df.isnull().sum()\n",
    "\n",
    "missing_percentage = (df.isnull().mean() * 100).round(2)\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    'Amount': missing_count,\n",
    "    'Percentage (%)': missing_percentage\n",
    "}).sort_values(by='Percentage (%)', ascending=True)\n",
    "\n",
    "print(missing_info)\n",
    "\n",
    "\n",
    "most_frequent_value_Edlevel = df['EdLevel'].mode()[0]\n",
    "print(f\"Most filled in values: {most_frequent_value_Edlevel}\")\n",
    "\n",
    "df['EdLevel'] = df['EdLevel'].fillna(most_frequent_value_Edlevel)\n",
    "\n",
    "print(f\"Amount of missing values after imputation EdLevel: {df['EdLevel'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Normalizing Compensation Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Normalize Compensation Data Using ConvertedCompYearly**\n",
    "   1. Use the ConvertedCompYearly column for compensation analysis as the normalized annual compensation is already provided.\n",
    "   2. Check for missing values in ConvertedCompYearly and handle them if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of missing salary: 0\n",
      "Percentage of missing salary: 0.00%\n",
      "The median of the Salary is: 65000.0\n",
      "Amount of missing values after imputation EdLevel: 0\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "missing_comp = df['ConvertedCompYearly'].isnull().sum()\n",
    "percent_missing = (missing_comp / len(df)) * 100\n",
    "\n",
    "print(f\"Amount of missing salary: {missing_comp}\")\n",
    "print(f\"Percentage of missing salary: {percent_missing:.2f}%\")\n",
    "\n",
    "median_salary = df['ConvertedCompYearly'].median()\n",
    "print(f\"The median of the Salary is: {median_salary}\")\n",
    "\n",
    "df['ConvertedCompYearly'] = df['ConvertedCompYearly'].fillna(median_salary)\n",
    "\n",
    "print(f\"Amount of missing values after imputation EdLevel: {df['ConvertedCompYearly'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Summary and Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this lab, you focused on identifying and removing duplicate rows.**\n",
    "\n",
    "- You handled missing values by imputing the most frequent value in a chosen column.\n",
    "\n",
    "- You used ConvertedCompYearly for compensation normalization and handled missing values.\n",
    "\n",
    "- For further analysis, consider exploring other columns or visualizing the cleaned dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2024-11-05|1.2|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-24|1.1|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-23|1.0|Raghul Ramesh|Created lab|\n",
    "\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "2116052544ce403759eef2159eb3d21f1d38e895d652bcaffa36a5791482361d"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
